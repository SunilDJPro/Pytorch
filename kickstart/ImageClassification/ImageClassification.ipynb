{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5ab422d",
   "metadata": {},
   "source": [
    "Refer https://www.learnpytorch.io for further concepts on PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bead8fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "\n",
    "from torchvision import transforms\n",
    "\n",
    "from PIL import Image, ImageFile\n",
    "\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1ea73f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6d9e516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading 1393 images\n",
      "Error downloading http://www.off-n-trottin.com/images/Breyers%20and%20Kittens%20035.jpg\n",
      "Error downloading http://www.arar93.dsl.pipex.com/mds975/Images/c_ronald_ginger_cat_01.jpg\n",
      "Error downloading http://www.unknownhighway.com/images/uploads/littletigercat-12-20-07-small.jpg\n",
      "Error downloading http://www.whitelightening.net/BuzzellTest/Creative/Tripp-TigerCat.jpg\n",
      "Error downloading http://www1.istockphoto.com/file_thumbview_approve/2754709/2/istockphoto_2754709_white_tiger.jpg\n",
      "Error downloading http://www.thebassethound.com/images/king1-sm.jpg\n",
      "Error downloading http://www.salmonherder.com/silver031.jpg\n",
      "Error downloading http://www.kenairiverhideaway.com/pix1/pat3.jpg\n",
      "Error downloading http://photos.oregonlive.com/photogallery/f43aa33cdff2bbd5e0173ab7a9460f04.jpg\n",
      "Error downloading http://image59.webshots.com/459/3/97/24/2362397240073428963uOVsAS_ph.jpg\n",
      "Error downloading http://www.atmos.washington.edu/~mantua/images/silver2.gif\n",
      "Error downloading http://www.alaskafishingandlodging.com/silver_salmon/photos/silver_salmon_002.jpg\n",
      "Error downloading http://www.fish4salmon.com/pictures/silvers/Ultralight_salmon_fishing_small.jpg\n",
      "Error downloading http://www.portlandsalmonfishing.com/images/prices_pg/coho_salmon_sm.jpg\n",
      "Error downloading http://www.boknowsfishing.com/images/Silver1.jpg\n"
     ]
    }
   ],
   "source": [
    "#!python3 download.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "58ce3754",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_image(path):\n",
    "    try:\n",
    "        im = Image.open(path)\n",
    "        return True\n",
    "    except:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe66376",
   "metadata": {},
   "source": [
    "### Image Transforms (Resize, Tensor Convertion, ImageNet mean, std)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2431a23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_transforms = transforms.Compose([\n",
    "    transforms.Resize((64,64)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) #Avoid exploding gradient problem\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fc1cef53",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path = \"./train/\"\n",
    "train_data = torchvision.datasets.ImageFolder(root=train_data_path, transform=img_transforms, is_valid_file=check_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6fb18252",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data_path = \"./val/\"\n",
    "val_data = torchvision.datasets.ImageFolder(root=val_data_path,transform=img_transforms, is_valid_file=check_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c03175c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_path = \"./test/\"\n",
    "test_data = torchvision.datasets.ImageFolder(root=train_data_path, transform=img_transforms, is_valid_file=check_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c8baf562",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c633d040",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size)\n",
    "val_data_loader = torch.utils.data.DataLoader(val_data, batch_size=batch_size)\n",
    "test_data_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db66039",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8b411d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNet,self).__init__()\n",
    "        self.fc1 = nn.Linear(12288, 84)\n",
    "        self.fc2 = nn.Linear(84, 50)\n",
    "        self.fc3 = nn.Linear(50, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 12288) # Convert to 1D Vector\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.softmax(self.fc3(x))\n",
    "        return x\n",
    "    \n",
    "simplenet = SimpleNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "00587024",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(simplenet.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b41bb1",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "64c1b176",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleNet(\n",
       "  (fc1): Linear(in_features=12288, out_features=84, bias=True)\n",
       "  (fc2): Linear(in_features=84, out_features=50, bias=True)\n",
       "  (fc3): Linear(in_features=50, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    \n",
    "simplenet.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "36b8d7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, loss_fn, train_loader, val_loader, epochs=20, device=\"cuda\"):\n",
    "    for epoch in range(epochs):\n",
    "        training_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "        model.train()\n",
    "        \n",
    "        for batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            inputs, targets = batch\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            output = model(inputs)\n",
    "            loss = loss_fn(output, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            training_loss += loss.data.item()*inputs.size(0)\n",
    "        training_loss /= len(train_loader.dataset)\n",
    "    \n",
    "        model.eval()\n",
    "        num_correct = 0\n",
    "        num_examples = 0\n",
    "    \n",
    "        for batch in val_loader:\n",
    "            inputs, targets = batch\n",
    "            inputs = inputs.to(device)\n",
    "            output = model(inputs)\n",
    "            targets = targets.to(device)\n",
    "            loss = loss_fn(output,targets)\n",
    "            valid_loss += loss.data.item()\n",
    "            correct = torch.eq(torch.max(F.softmax(output), dim=1)[1],targets).view(-1)\n",
    "            num_correct += torch.sum(correct).item()\n",
    "            num_examples += correct.shape[0]\n",
    "        \n",
    "        valid_loss /= len(val_loader.dataset)\n",
    "    \n",
    "        print('Epoch: {}, Training Loss: {:.2f}, Validation Loss: {:.2f}, accuracy = {:.2f}'.format(epoch, training_loss, valid_loss, num_correct / num_examples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "6a847c74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3768/2388696160.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = F.softmax(self.fc3(x))\n",
      "/tmp/ipykernel_3768/2192173827.py:30: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  correct = torch.eq(torch.max(F.softmax(output), dim=1)[1],targets).view(-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Training Loss: 0.41, Validation Loss: 0.01, accuracy = 0.91\n",
      "Epoch: 1, Training Loss: 0.41, Validation Loss: 0.01, accuracy = 0.91\n",
      "Epoch: 2, Training Loss: 0.40, Validation Loss: 0.01, accuracy = 0.91\n",
      "Epoch: 3, Training Loss: 0.40, Validation Loss: 0.01, accuracy = 0.91\n",
      "Epoch: 4, Training Loss: 0.40, Validation Loss: 0.01, accuracy = 0.91\n",
      "Epoch: 5, Training Loss: 0.40, Validation Loss: 0.01, accuracy = 0.91\n",
      "Epoch: 6, Training Loss: 0.40, Validation Loss: 0.01, accuracy = 0.91\n",
      "Epoch: 7, Training Loss: 0.40, Validation Loss: 0.01, accuracy = 0.92\n",
      "Epoch: 8, Training Loss: 0.40, Validation Loss: 0.01, accuracy = 0.92\n",
      "Epoch: 9, Training Loss: 0.40, Validation Loss: 0.01, accuracy = 0.92\n",
      "Epoch: 10, Training Loss: 0.40, Validation Loss: 0.01, accuracy = 0.92\n",
      "Epoch: 11, Training Loss: 0.40, Validation Loss: 0.01, accuracy = 0.92\n",
      "Epoch: 12, Training Loss: 0.40, Validation Loss: 0.01, accuracy = 0.92\n",
      "Epoch: 13, Training Loss: 0.40, Validation Loss: 0.01, accuracy = 0.92\n",
      "Epoch: 14, Training Loss: 0.40, Validation Loss: 0.01, accuracy = 0.92\n",
      "Epoch: 15, Training Loss: 0.40, Validation Loss: 0.01, accuracy = 0.92\n",
      "Epoch: 16, Training Loss: 0.39, Validation Loss: 0.01, accuracy = 0.92\n",
      "Epoch: 17, Training Loss: 0.39, Validation Loss: 0.01, accuracy = 0.92\n",
      "Epoch: 18, Training Loss: 0.40, Validation Loss: 0.01, accuracy = 0.92\n",
      "Epoch: 19, Training Loss: 0.39, Validation Loss: 0.01, accuracy = 0.92\n"
     ]
    }
   ],
   "source": [
    "train(simplenet, optimizer, torch.nn.CrossEntropyLoss(), train_data_loader, test_data_loader, epochs=20, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc4ee06",
   "metadata": {},
   "source": [
    "## Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "957c4723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fish\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3768/2388696160.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = F.softmax(self.fc3(x))\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "labels = ['cat', 'fish']\n",
    "\n",
    "FILENAME = \"./val/fish/silver24.jpg\"\n",
    "\n",
    "img = Image.open(FILENAME)\n",
    "img = img_transforms(img).to(device)\n",
    "img = torch.unsqueeze(img, 0)\n",
    "\n",
    "simplenet.eval()\n",
    "prediction = F.softmax(simplenet(img), dim=1)\n",
    "prediction = prediction.argmax()\n",
    "print(labels[prediction])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "3c82d854",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(simplenet, \"./model/simplenet1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "0e37b604",
   "metadata": {},
   "outputs": [],
   "source": [
    "simplenet = torch.load(\"./model/simplenet1\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "a2bfc3e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.save(simplenet.state_dict(), \"./model/simplenet2\")    \n",
    "simplenet = SimpleNet()\n",
    "simplenet_state_dict = torch.load(\"./model/simplenet2\")\n",
    "simplenet.load_state_dict(simplenet_state_dict)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c528738",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
